{
    "# How to Report an Issue on GitHub": "# 如何在 GitHub 上报告问题",
    "## Download Model": "## 下载模型",
    "## Download Pretrained Models": "## 下载预训练模型",
    "## Drop files": "## 拖放文件",
    "## Voice Blender": "## 声音混合器",
    "0 to ∞ separated by -": "0 到 ∞，用 - 分隔",
    "1. Click on the 'Record Screen' button below to start recording the issue you are experiencing.": "1. 点击下方的“录制屏幕”按钮，开始录制您遇到的问题。",
    "2. Once you have finished recording the issue, click on the 'Stop Recording' button (the same button, but the label changes depending on whether you are actively recording or not).": "2. 录制完问题后，点击“停止录制”按钮（按钮是同一个，但标签会根据您是否正在录制而变化）。",
    "3. Go to [GitHub Issues](https://github.com/IAHispano/Applio/issues) and click on the 'New Issue' button.": "3. 前往 [GitHub Issues](https://github.com/IAHispano/Applio/issues) 并点击“新建问题”按钮。",
    "4. Complete the provided issue template, ensuring to include details as needed, and utilize the assets section to upload the recorded file from the previous step.": "4. 填写所提供的问题模板，确保按需提供详细信息，并使用附件区域上传上一步录制的文件。",
    "A simple, high-quality voice conversion tool focused on ease of use and performance.": "一款简单、高质量的变声工具，专注于易用性和性能。",
    "Adding several silent files to the training set enables the model to handle pure silence in inferred audio files. Select 0 if your dataset is clean and already contains segments of pure silence.": "向训练集中添加多个静音文件，可以使模型能够处理推理音频文件中的纯静音。如果您的数据集是干净的并且已经包含纯静音片段，请选择 0。",
    "Adjust the input audio pitch to match the voice model range.": "调整输入音频的音高以匹配声音模型的音域范围。",
    "Adjusting the position more towards one side or the other will make the model more similar to the first or second.": "将滑块位置更偏向一侧或另一侧，将使模型更像第一个或第二个声音。",
    "Adjusts the final volume of the converted voice after processing.": "调整处理后已转换语音的最终音量。",
    "Adjusts the input volume before processing. Prevents clipping or boosts a quiet mic.": "调整处理前的输入音量。可防止爆音或增强过轻的麦克风音量。",
    "Adjusts the volume of the monitor feed, independent of the main output.": "独立于主输出，调整监听音频的音量。",
    "Advanced Settings": "高级设置",
    "Amount of extra audio processed to provide context to the model. Improves conversion quality at the cost of higher CPU usage.": "为给模型提供上下文而处理的额外音频量。它能提高转换质量，但会增加 CPU 使用率。",
    "And select the sampling rate.": "并选择采样率。",
    "Apply a soft autotune to your inferences, recommended for singing conversions.": "为您的推理结果应用柔和的自动音高校正，推荐用于歌唱转换。",
    "Apply bitcrush to the audio.": "对音频应用比特失真效果。",
    "Apply chorus to the audio.": "对音频应用合唱效果。",
    "Apply clipping to the audio.": "对音频应用削波效果。",
    "Apply compressor to the audio.": "对音频应用压缩器效果。",
    "Apply delay to the audio.": "对音频应用延迟效果。",
    "Apply distortion to the audio.": "对音频应用失真效果。",
    "Apply gain to the audio.": "对音频应用增益效果。",
    "Apply limiter to the audio.": "对音频应用限制器效果。",
    "Apply pitch shift to the audio.": "对音频应用变调效果。",
    "Apply reverb to the audio.": "对音频应用混响效果。",
    "Architecture": "模型架构",
    "Audio Analyzer": "音频分析器",
    "Audio Settings": "音频设置",
    "Audio buffer size in milliseconds. Lower values may reduce latency but increase CPU load.": "音频缓冲区大小（单位：毫秒）。值越低延迟越小，但会增加 CPU 负载。",
    "Audio cutting": "音频切割",
    "Audio file slicing method: Select 'Skip' if the files are already pre-sliced, 'Simple' if excessive silence has already been removed from the files, or 'Automatic' for automatic silence detection and slicing around it.": "音频文件切片方法：如果文件已经预先切片，请选择“跳过”；如果文件中多余的静音已被移除，请选择“简单”；如果需要自动检测静音并围绕其进行切片，请选择“自动”。",
    "Audio normalization: Select 'none' if the files are already normalized, 'pre' to normalize the entire input file at once, or 'post' to normalize each slice individually.": "音频归一化：如果文件已经归一化，请选择“无”；如果需要一次性归一化整个输入文件，请选择“预处理”；如果需要单独归一化每个切片，请选择“后处理”。",
    "Autotune": "自动音高修正",
    "Autotune Strength": "自动音高修正强度",
    "Batch": "批处理",
    "Batch Size": "批处理大小",
    "Bitcrush": "比特失真",
    "Bitcrush Bit Depth": "比特失真位深度",
    "Blend Ratio": "混合比例",
    "Browse presets for formanting": "浏览共振峰预设",
    "CPU Cores": "CPU 核心数",
    "Cache Dataset in GPU": "在 GPU 中缓存数据集",
    "Cache the dataset in GPU memory to speed up the training process.": "将数据集缓存到 GPU 内存中以加快训练过程。",
    "Check for updates": "检查更新",
    "Check which version of Applio is the latest to see if you need to update.": "检查 Applio 的最新版本，看看您是否需要更新。",
    "Checkpointing": "检查点",
    "Choose the model architecture:\n- **RVC (V2)**: Default option, compatible with all clients.\n- **Applio**: Advanced quality with improved vocoders and higher sample rates, Applio-only.": "选择模型架构：\n- **RVC (V2)**：默认选项，与所有客户端兼容。\n- **Applio**：质量更高，具有改进的声码器和更高的采样率，仅限 Applio 使用。",
    "Choose the vocoder for audio synthesis:\n- **HiFi-GAN**: Default option, compatible with all clients.\n- **MRF HiFi-GAN**: Higher fidelity, Applio-only.\n- **RefineGAN**: Superior audio quality, Applio-only.": "选择用于音频合成的声码器：\n- **HiFi-GAN**：默认选项，与所有客户端兼容。\n- **MRF HiFi-GAN**：保真度更高，仅限 Applio 使用。\n- **RefineGAN**：音质卓越，仅限 Applio 使用。",
    "Chorus": "合唱",
    "Chorus Center Delay ms": "合唱中心延迟（毫秒）",
    "Chorus Depth": "合唱深度",
    "Chorus Feedback": "合唱反馈",
    "Chorus Mix": "合唱混合",
    "Chorus Rate Hz": "合唱速率（赫兹）",
    "Chunk Size (ms)": "区块大小 (ms)",
    "Chunk length (sec)": "切片长度（秒）",
    "Clean Audio": "音频降噪",
    "Clean Strength": "降噪强度",
    "Clean your audio output using noise detection algorithms, recommended for speaking audios.": "使用噪声检测算法清理您的输出音频，推荐用于语音音频。",
    "Clear Outputs (Deletes all audios in assets/audios)": "清除输出（删除 assets/audios 中的所有音频）",
    "Click the refresh button to see the pretrained file in the dropdown menu.": "点击刷新按钮以在下拉菜单中查看预训练文件。",
    "Clipping": "削波",
    "Clipping Threshold": "削波阈值",
    "Compressor": "压缩器",
    "Compressor Attack ms": "压缩器启动时间（毫秒）",
    "Compressor Ratio": "压缩器比率",
    "Compressor Release ms": "压缩器释放时间（毫秒）",
    "Compressor Threshold dB": "压缩器阈值（分贝）",
    "Convert": "转换",
    "Crossfade Overlap Size (s)": "交叉淡化重叠大小 (s)",
    "Custom Embedder": "自定义嵌入器",
    "Custom Pretrained": "自定义预训练模型",
    "Custom Pretrained D": "自定义预训练模型 D",
    "Custom Pretrained G": "自定义预训练模型 G",
    "Dataset Creator": "数据集创建器",
    "Dataset Name": "数据集名称",
    "Dataset Path": "数据集路径",
    "Default value is 1.0": "默认值为 1.0",
    "Delay": "延迟",
    "Delay Feedback": "延迟反馈",
    "Delay Mix": "延迟混合",
    "Delay Seconds": "延迟秒数",
    "Detect overtraining to prevent the model from learning the training data too well and losing the ability to generalize to new data.": "检测过拟合，以防止模型过度学习训练数据而失去对新数据的泛化能力。",
    "Determine at how many epochs the model will saved at.": "设置模型每隔多少个 epoch 保存一次。",
    "Distortion": "失真",
    "Distortion Gain": "失真增益",
    "Download": "下载",
    "Download Model": "下载模型",
    "Drag and drop your model here": "将您的模型拖放到此处",
    "Drag your .pth file and .index file into this space. Drag one and then the other.": "将您的 .pth 文件和 .index 文件拖入此区域。先拖一个，再拖另一个。",
    "Drag your plugin.zip to install it": "拖动您的 plugin.zip 文件以进行安装",
    "Duration of the fade between audio chunks to prevent clicks. Higher values create smoother transitions but may increase latency.": "音频块之间交叉淡化的持续时间，以防止产生咔哒声。值越高过渡越平滑，但可能会增加延迟。",
    "Embedder Model": "嵌入器模型",
    "Enable Applio integration with Discord presence": "启用 Applio 与 Discord 状态的集成",
    "Enable VAD": "启用 VAD",
    "Enable formant shifting. Used for male to female and vice-versa convertions.": "启用共振峰移位。用于男声转女声或女声转男声的转换。",
    "Enable this setting only if you are training a new model from scratch or restarting the training. Deletes all previously generated weights and tensorboard logs.": "仅当您从头开始训练新模型或重新开始训练时才启用此设置。此操作会删除所有先前生成的权重和 Tensorboard 日志。",
    "Enables Voice Activity Detection to only process audio when you are speaking, saving CPU.": "启用语音活动检测 (VAD)，仅在您说话时处理音频，以节省 CPU 资源。",
    "Enables memory-efficient training. This reduces VRAM usage at the cost of slower training speed. It is useful for GPUs with limited memory (e.g., <6GB VRAM) or when training with a batch size larger than what your GPU can normally accommodate.": "启用内存高效训练。这会降低 VRAM 使用量，但代价是训练速度变慢。此功能对于显存有限的 GPU（例如，<6GB VRAM）或当训练的批处理大小超出 GPU 正常承受范围时非常有用。",
    "Enabling this setting will result in the G and D files saving only their most recent versions, effectively conserving storage space.": "启用此设置将导致 G 和 D 文件仅保存其最新版本，从而有效节省存储空间。",
    "Enter dataset name": "输入数据集名称",
    "Enter input path": "输入路径",
    "Enter model name": "输入模型名称",
    "Enter output path": "输入输出路径",
    "Enter path to model": "输入模型路径",
    "Enter preset name": "输入预设名称",
    "Enter text to synthesize": "输入要合成的文本",
    "Enter the text to synthesize.": "输入要合成的文本。",
    "Enter your nickname": "输入您的昵称",
    "Exclusive Mode (WASAPI)": "独占模式 (WASAPI)",
    "Export Audio": "导出音频",
    "Export Format": "导出格式",
    "Export Model": "导出模型",
    "Export Preset": "导出预设",
    "Exported Index File": "已导出的索引文件",
    "Exported Pth file": "已导出的 Pth 文件",
    "Extra": "额外",
    "Extra Conversion Size (s)": "额外转换大小 (s)",
    "Extract": "提取",
    "Extract F0 Curve": "提取 F0 曲线",
    "Extract Features": "提取特征",
    "F0 Curve": "F0 曲线",
    "File to Speech": "文件转语音",
    "Folder Name": "文件夹名称",
    "For ASIO drivers, selects a specific input channel. Leave at -1 for default.": "用于 ASIO 驱动，选择一个特定的输入通道。保留 -1 为默认值。",
    "For ASIO drivers, selects a specific monitor output channel. Leave at -1 for default.": "用于 ASIO 驱动，选择一个特定的监听输出通道。保留 -1 为默认值。",
    "For ASIO drivers, selects a specific output channel. Leave at -1 for default.": "用于 ASIO 驱动，选择一个特定的输出通道。保留 -1 为默认值。",
    "For WASAPI (Windows), gives the app exclusive control for potentially lower latency.": "用于 WASAPI (Windows)，授予应用独占控制权以可能降低延迟。",
    "Formant Shifting": "共振峰移位",
    "Fresh Training": "全新训练",
    "Fusion": "融合",
    "GPU Information": "GPU 信息",
    "GPU Number": "GPU 编号",
    "Gain": "增益",
    "Gain dB": "增益（分贝）",
    "General": "通用",
    "Generate Index": "生成索引",
    "Get information about the audio": "获取有关音频的信息",
    "I agree to the terms of use": "我同意使用条款",
    "Increase or decrease TTS speed.": "增加或减少 TTS 语速。",
    "Index Algorithm": "索引算法",
    "Index File": "索引文件",
    "Inference": "推理",
    "Influence exerted by the index file; a higher value corresponds to greater influence. However, opting for lower values can help mitigate artifacts present in the audio.": "索引文件所施加的影响；值越高，影响越大。然而，选择较低的值有助于减轻音频中存在的杂音。",
    "Input ASIO Channel": "输入 ASIO 通道",
    "Input Device": "输入设备",
    "Input Folder": "输入文件夹",
    "Input Gain (%)": "输入增益 (%)",
    "Input path for text file": "文本文件的输入路径",
    "Introduce the model link": "输入模型链接",
    "Introduce the model pth path": "输入模型 pth 路径",
    "It will activate the possibility of displaying the current Applio activity in Discord.": "此选项将激活在 Discord 中显示当前 Applio 活动的功能。",
    "It's advisable to align it with the available VRAM of your GPU. A setting of 4 offers improved accuracy but slower processing, while 8 provides faster and standard results.": "建议根据您 GPU 的可用 VRAM 进行调整。设置为 4 可提供更高的精度但处理速度较慢，而设置为 8 可提供更快和标准的结果。",
    "It's recommended keep deactivate this option if your dataset has already been processed.": "如果您的数据集已经处理过，建议禁用此选项。",
    "It's recommended to deactivate this option if your dataset has already been processed.": "如果您的数据集已经处理过，建议禁用此选项。",
    "KMeans is a clustering algorithm that divides the dataset into K clusters. This setting is particularly useful for large datasets.": "KMeans 是一种将数据集划分为 K 个簇的聚类算法。此设置对大型数据集特别有用。",
    "Language": "语言",
    "Length of the audio slice for 'Simple' method.": "“简单”方法下音频切片的长度。",
    "Length of the overlap between slices for 'Simple' method.": "“简单”方法下切片之间的重叠长度。",
    "Limiter": "限制器",
    "Limiter Release Time": "限制器释放时间",
    "Limiter Threshold dB": "限制器阈值（分贝）",
    "Male voice models typically use 155.0 and female voice models typically use 255.0.": "男声模型通常使用 155.0，女声模型通常使用 255.0。",
    "Model Author Name": "模型作者名称",
    "Model Link": "模型链接",
    "Model Name": "模型名称",
    "Model Settings": "模型设置",
    "Model information": "模型信息",
    "Model used for learning speaker embedding.": "用于学习说话人嵌入的模型。",
    "Monitor ASIO Channel": "监听 ASIO 通道",
    "Monitor Device": "监听设备",
    "Monitor Gain (%)": "监听增益 (%)",
    "Move files to custom embedder folder": "将文件移动到自定义嵌入器文件夹",
    "Name of the new dataset.": "新数据集的名称。",
    "Name of the new model.": "新模型的名称。",
    "Noise Reduction": "降噪",
    "Noise Reduction Strength": "降噪强度",
    "Noise filter": "噪声滤波器",
    "Normalization mode": "归一化模式",
    "Output ASIO Channel": "输出 ASIO 通道",
    "Output Device": "输出设备",
    "Output Folder": "输出文件夹",
    "Output Gain (%)": "输出增益 (%)",
    "Output Information": "输出信息",
    "Output Path": "输出路径",
    "Output Path for RVC Audio": "RVC 音频输出路径",
    "Output Path for TTS Audio": "TTS 音频输出路径",
    "Overlap length (sec)": "重叠长度（秒）",
    "Overtraining Detector": "过拟合检测器",
    "Overtraining Detector Settings": "过拟合检测器设置",
    "Overtraining Threshold": "过拟合阈值",
    "Path to Model": "模型路径",
    "Path to the dataset folder.": "数据集文件夹的路径。",
    "Performance Settings": "性能设置",
    "Pitch": "音高",
    "Pitch Shift": "变调",
    "Pitch Shift Semitones": "变调半音数",
    "Pitch extraction algorithm": "音高提取算法",
    "Pitch extraction algorithm to use for the audio conversion. The default algorithm is rmvpe, which is recommended for most cases.": "用于音频转换的音高提取算法。默认算法是 rmvpe，推荐在大多数情况下使用。",
    "Please ensure compliance with the terms and conditions detailed in [this document](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md) before proceeding with your inference.": "在进行推理之前，请确保您遵守[此文档](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md)中详述的条款和条件。",
    "Please ensure compliance with the terms and conditions detailed in [this document](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md) before proceeding with your realtime.": "在进行实时转换前，请确保您遵守[此文档](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md)中详述的条款和条件。",
    "Please ensure compliance with the terms and conditions detailed in [this document](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md) before proceeding with your training.": "在进行训练之前，请确保您遵守[此文档](https://github.com/IAHispano/Applio/blob/main/TERMS_OF_USE.md)中详述的条款和条件。",
    "Plugin Installer": "插件安装器",
    "Plugins": "插件",
    "Post-Process": "后处理",
    "Post-process the audio to apply effects to the output.": "对音频进行后处理，为输出添加效果。",
    "Precision": "精度",
    "Preprocess": "预处理",
    "Preprocess Dataset": "预处理数据集",
    "Preset Name": "预设名称",
    "Preset Settings": "预设设置",
    "Presets are located in /assets/formant_shift folder": "预设位于 /assets/formant_shift 文件夹中",
    "Pretrained": "预训练模型",
    "Pretrained Custom Settings": "自定义预训练模型设置",
    "Proposed Pitch": "建议音高",
    "Proposed Pitch Threshold": "建议音高阈值",
    "Protect Voiceless Consonants": "保护清辅音",
    "Pth file": "Pth 文件",
    "Quefrency for formant shifting": "用于共振峰移位的 Quefrency",
    "Realtime": "实时",
    "Record Screen": "录制屏幕",
    "Refresh": "刷新",
    "Refresh Audio Devices": "刷新音频设备",
    "Refresh Custom Pretraineds": "刷新自定义预训练模型",
    "Refresh Presets": "刷新预设",
    "Refresh embedders": "刷新嵌入器",
    "Report a Bug": "报告错误",
    "Restart Applio": "重启 Applio",
    "Reverb": "混响",
    "Reverb Damping": "混响阻尼",
    "Reverb Dry Gain": "混响干声增益",
    "Reverb Freeze Mode": "混响冻结模式",
    "Reverb Room Size": "混响空间大小",
    "Reverb Wet Gain": "混响湿声增益",
    "Reverb Width": "混响宽度",
    "Safeguard distinct consonants and breathing sounds to prevent electro-acoustic tearing and other artifacts. Pulling the parameter to its maximum value of 0.5 offers comprehensive protection. However, reducing this value might decrease the extent of protection while potentially mitigating the indexing effect.": "保护独特的辅音和呼吸声，以防止电声撕裂和其他杂音。将参数拉到最大值 0.5 可提供全面保护。然而，降低此值可能会减少保护程度，但可能减轻索引效应。",
    "Sampling Rate": "采样率",
    "Save Every Epoch": "每轮都保存",
    "Save Every Weights": "保存每个权重",
    "Save Only Latest": "仅保存最新",
    "Search Feature Ratio": "特征检索比例",
    "See Model Information": "查看模型信息",
    "Select Audio": "选择音频",
    "Select Custom Embedder": "选择自定义嵌入器",
    "Select Custom Preset": "选择自定义预设",
    "Select file to import": "选择要导入的文件",
    "Select the TTS voice to use for the conversion.": "选择用于转换的 TTS 声音。",
    "Select the audio to convert.": "选择要转换的音频。",
    "Select the custom pretrained model for the discriminator.": "为判别器选择自定义预训练模型。",
    "Select the custom pretrained model for the generator.": "为生成器选择自定义预训练模型。",
    "Select the device for monitoring your voice (e.g., your headphones).": "选择用于监听您声音的设备（例如：耳机）。",
    "Select the device where the final converted voice will be sent (e.g., a virtual cable).": "选择用于发送最终转换后语音的设备（例如：虚拟声卡）。",
    "Select the folder containing the audios to convert.": "选择包含要转换的音频的文件夹。",
    "Select the folder where the output audios will be saved.": "选择保存输出音频的文件夹。",
    "Select the format to export the audio.": "选择导出音频的格式。",
    "Select the index file to be exported": "选择要导出的索引文件",
    "Select the index file to use for the conversion.": "选择用于转换的索引文件。",
    "Select the language you want to use. (Requires restarting Applio)": "选择您想使用的语言。（需要重启 Applio）",
    "Select the microphone or audio interface you will be speaking into.": "选择您将要使用的麦克风或音频接口。",
    "Select the precision you want to use for training and inference.": "选择您想用于训练和推理的精度。",
    "Select the pretrained model you want to download.": "选择您想下载的预训练模型。",
    "Select the pth file to be exported": "选择要导出的 pth 文件",
    "Select the speaker ID to use for the conversion.": "选择用于转换的说话人 ID。",
    "Select the theme you want to use. (Requires restarting Applio)": "选择您想使用的主题。（需要重启 Applio）",
    "Select the voice model to use for the conversion.": "选择用于转换的声音模型。",
    "Select two voice models, set your desired blend percentage, and blend them into an entirely new voice.": "选择两个声音模型，设置您想要的混合百分比，然后将它们融合成一个全新的声音。",
    "Set name": "设置名称",
    "Set the autotune strength - the more you increase it the more it will snap to the chromatic grid.": "设置自动音高修正的强度 - 强度越高，音高就越会贴合到半音网格上。",
    "Set the bitcrush bit depth.": "设置比特失真的位深度。",
    "Set the chorus center delay ms.": "设置合唱的中心延迟（毫秒）。",
    "Set the chorus depth.": "设置合唱的深度。",
    "Set the chorus feedback.": "设置合唱的反馈。",
    "Set the chorus mix.": "设置合唱的混合度。",
    "Set the chorus rate Hz.": "设置合唱的速率（赫兹）。",
    "Set the clean-up level to the audio you want, the more you increase it the more it will clean up, but it is possible that the audio will be more compressed.": "为您想要的音频设置清理级别，级别越高，清理效果越好，但音频可能会被更多地压缩。",
    "Set the clipping threshold.": "设置削波阈值。",
    "Set the compressor attack ms.": "设置压缩器的启动时间（毫秒）。",
    "Set the compressor ratio.": "设置压缩器的比率。",
    "Set the compressor release ms.": "设置压缩器的释放时间（毫秒）。",
    "Set the compressor threshold dB.": "设置压缩器的阈值（分贝）。",
    "Set the damping of the reverb.": "设置混响的阻尼。",
    "Set the delay feedback.": "设置延迟的反馈。",
    "Set the delay mix.": "设置延迟的混合度。",
    "Set the delay seconds.": "设置延迟的秒数。",
    "Set the distortion gain.": "设置失真的增益。",
    "Set the dry gain of the reverb.": "设置混响的干声增益。",
    "Set the freeze mode of the reverb.": "设置混响的冻结模式。",
    "Set the gain dB.": "设置增益（分贝）。",
    "Set the limiter release time.": "设置限制器的释放时间。",
    "Set the limiter threshold dB.": "设置限制器的阈值（分贝）。",
    "Set the maximum number of epochs you want your model to stop training if no improvement is detected.": "设置在未检测到改进时模型停止训练的最大 epoch 数。",
    "Set the pitch of the audio, the higher the value, the higher the pitch.": "设置音频的音高，值越高，音高越高。",
    "Set the pitch shift semitones.": "设置变调的半音数。",
    "Set the room size of the reverb.": "设置混响的空间大小。",
    "Set the wet gain of the reverb.": "设置混响的湿声增益。",
    "Set the width of the reverb.": "设置混响的宽度。",
    "Settings": "设置",
    "Silence Threshold (dB)": "静音阈值 (dB)",
    "Silent training files": "静音训练文件",
    "Single": "单个",
    "Speaker ID": "说话人 ID",
    "Specifies the overall quantity of epochs for the model training process.": "指定模型训练过程的总 epoch 数量。",
    "Specify the number of GPUs you wish to utilize for extracting by entering them separated by hyphens (-).": "输入您希望用于提取的 GPU 编号，用连字符（-）分隔。",
    "Split Audio": "分割音频",
    "Split the audio into chunks for inference to obtain better results in some cases.": "将音频分割成块进行推理，以在某些情况下获得更好的结果。",
    "Start": "开始",
    "Start Training": "开始训练",
    "Status": "状态",
    "Stop": "停止",
    "Stop Training": "停止训练",
    "Stop convert": "停止转换",
    "Substitute or blend with the volume envelope of the output. The closer the ratio is to 1, the more the output envelope is employed.": "替换或混合输出的音量包络。比率越接近 1，使用的输出包络就越多。",
    "TTS": "TTS",
    "TTS Speed": "TTS 语速",
    "TTS Voices": "TTS 声音",
    "Text to Speech": "文本转语音",
    "Text to Synthesize": "要合成的文本",
    "The GPU information will be displayed here.": "GPU 信息将在此处显示。",
    "The audio file has been successfully added to the dataset. Please click the preprocess button.": "音频文件已成功添加到数据集。请点击预处理按钮。",
    "The button 'Upload' is only for google colab: Uploads the exported files to the ApplioExported folder in your Google Drive.": "“上传”按钮仅适用于 Google Colab：将导出的文件上传到您 Google Drive 中的 ApplioExported 文件夹。",
    "The f0 curve represents the variations in the base frequency of a voice over time, showing how pitch rises and falls.": "f0 曲线表示声音基频随时间的变化，显示音高如何上升和下降。",
    "The file you dropped is not a valid pretrained file. Please try again.": "您拖放的文件不是有效的预训练文件。请重试。",
    "The name that will appear in the model information.": "将出现在模型信息中的名称。",
    "The number of CPU cores to use in the extraction process. The default setting are your cpu cores, which is recommended for most cases.": "提取过程中使用的 CPU 核心数。默认设置为您的 CPU 核心数，这在大多数情况下是推荐的。",
    "The output information will be displayed here.": "输出信息将在此处显示。",
    "The path to the text file that contains content for text to speech.": "包含文本转语音内容的文本文件的路径。",
    "The path where the output audio will be saved, by default in assets/audios/output.wav": "输出音频的保存路径，默认为 assets/audios/output.wav",
    "The sampling rate of the audio files.": "音频文件的采样率。",
    "Theme": "主题",
    "This setting enables you to save the weights of the model at the conclusion of each epoch.": "此设置使您能够在每个 epoch 结束时保存模型的权重。",
    "Timbre for formant shifting": "用于共振峰移位的音色",
    "Total Epoch": "总轮数",
    "Training": "训练",
    "Unload Voice": "卸载声音",
    "Update precision": "更新精度",
    "Upload": "上传",
    "Upload .bin": "上传 .bin",
    "Upload .json": "上传 .json",
    "Upload Audio": "上传音频",
    "Upload Audio Dataset": "上传音频数据集",
    "Upload Pretrained Model": "上传预训练模型",
    "Upload a .txt file": "上传一个 .txt 文件",
    "Use Monitor Device": "使用监听设备",
    "Utilize pretrained models when training your own. This approach reduces training duration and enhances overall quality.": "训练您自己的模型时，请使用预训练模型。这种方法可以减少训练时间并提高整体质量。",
    "Utilizing custom pretrained models can lead to superior results, as selecting the most suitable pretrained models tailored to the specific use case can significantly enhance performance.": "使用自定义预训练模型可以获得更好的结果，因为选择最适合特定用例的预训练模型可以显著提高性能。",
    "Version Checker": "版本检查器",
    "View": "查看",
    "Vocoder": "声码器",
    "Voice Blender": "声音混合器",
    "Voice Model": "声音模型",
    "Volume Envelope": "音量包络",
    "Volume level below which audio is treated as silence and not processed. Helps to save CPU resources and reduce background noise.": "低于此音量级别的音频将被视为静音且不作处理。这有助于节省 CPU 资源并减少背景噪音。",
    "You can also use a custom path.": "您也可以使用自定义路径。",
    "[Support](https://discord.gg/urxFjYmYYh) — [GitHub](https://github.com/IAHispano/Applio)": "[支持](https://discord.gg/urxFjYmYYh) — [GitHub](https://github.com/IAHispano/Applio)"
}
